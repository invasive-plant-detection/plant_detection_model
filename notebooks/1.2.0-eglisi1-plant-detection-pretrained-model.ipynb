{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# basic plant detection for starting Bachelor thesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   classid                                         image_path  \\\n",
      "0  5328909  5328909/de73353bbf8431ec594df8c0c070fa5d562756...   \n",
      "1  5328909  5328909/cb1b1aac1895f8f5a52e1c85ef8ceae7580e68...   \n",
      "2  5328909  5328909/4bdb06e3f9b4b61c9ed2a269498d064b41b1d0...   \n",
      "3  5328909  5328909/2e5095764b764e63fca8150bab3aa1bbc2157a...   \n",
      "4  5328909  5328909/9886a43a74aa9c493667235bb98786df965706...   \n",
      "\n",
      "                       species       genus        family        order  \\\n",
      "0  sagittaria latifolia willd.  Sagittaria  Alismataceae  Alismatales   \n",
      "1  sagittaria latifolia willd.  Sagittaria  Alismataceae  Alismatales   \n",
      "2  sagittaria latifolia willd.  Sagittaria  Alismataceae  Alismatales   \n",
      "3  sagittaria latifolia willd.  Sagittaria  Alismataceae  Alismatales   \n",
      "4  sagittaria latifolia willd.  Sagittaria  Alismataceae  Alismatales   \n",
      "\n",
      "        class                                   image_backup_url  \n",
      "0  Liliopsida  https://lab.plantnet.org/LifeCLEF/PlantCLEF202...  \n",
      "1  Liliopsida  https://lab.plantnet.org/LifeCLEF/PlantCLEF202...  \n",
      "2  Liliopsida  https://lab.plantnet.org/LifeCLEF/PlantCLEF202...  \n",
      "3  Liliopsida  https://lab.plantnet.org/LifeCLEF/PlantCLEF202...  \n",
      "4  Liliopsida  https://lab.plantnet.org/LifeCLEF/PlantCLEF202...  \n"
     ]
    }
   ],
   "source": [
    "# load data PlantCLEF2022_trusted_training_metadata.csv form /data/01_raw/PlantCLEF2022_trusted_training_metadata.csv\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "file_path = \"../data/02_processed/merged_data.csv\"\n",
    "try:\n",
    "    data = pd.read_csv(file_path, delimiter=\";\")\n",
    "    if data.empty:\n",
    "        print(\"The CSV file is empty\")\n",
    "    else:\n",
    "        print(data.head())\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\n",
    "        f\"File not found: {file_path}. Please check the file path and that the file is downloaded.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## use the 5 most occuring species "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the 5 most occuring species in the dataset and remove the rest\n",
    "\n",
    "AMOUNT_OF_SPECIES = 5\n",
    "\n",
    "species = data[\"species\"].value_counts().head(AMOUNT_OF_SPECIES)\n",
    "species = species.index.tolist()\n",
    "data = data[data[\"species\"].isin(species)]\n",
    "\n",
    "species = data[\"species\"].unique()\n",
    "len(species)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## delete already existing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "temp_dir = \"temp\"\n",
    "\n",
    "# delete and create tmp dir to ensure it's empty\n",
    "os.system(f\"rm -rf {temp_dir}\")\n",
    "\n",
    "# Ensure the tmp/ directory exists\n",
    "os.makedirs(temp_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## download data per plant parallelized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "\n",
    "def download_image(index_url: str) -> None:\n",
    "    index, url = index_url\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        file_path = os.path.join(temp_dir, f\"{index}.jpg\")\n",
    "\n",
    "        with open(file_path, \"wb\") as file:\n",
    "            file.write(response.content)\n",
    "        # print(f\"Downloaded {url} to {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading {url}: {e}\")\n",
    "\n",
    "\n",
    "# Prepare a list of tuples containing the index and URL for each image\n",
    "index_url_list = [(index, row[\"image_backup_url\"]) for index, row in data.iterrows()]\n",
    "\n",
    "# Use ThreadPoolExecutor to download images in parallel\n",
    "with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "    executor.map(download_image, index_url_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add image path to metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classid</th>\n",
       "      <th>image_path</th>\n",
       "      <th>species</th>\n",
       "      <th>genus</th>\n",
       "      <th>family</th>\n",
       "      <th>order</th>\n",
       "      <th>class</th>\n",
       "      <th>image_backup_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>8002952</td>\n",
       "      <td>temp/580.jpg</td>\n",
       "      <td>ambrosia artemisiifolia l.</td>\n",
       "      <td>Ambrosia</td>\n",
       "      <td>Asteraceae</td>\n",
       "      <td>Asterales</td>\n",
       "      <td>Magnoliopsida</td>\n",
       "      <td>https://lab.plantnet.org/LifeCLEF/PlantCLEF202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>8002952</td>\n",
       "      <td>temp/581.jpg</td>\n",
       "      <td>ambrosia artemisiifolia l.</td>\n",
       "      <td>Ambrosia</td>\n",
       "      <td>Asteraceae</td>\n",
       "      <td>Asterales</td>\n",
       "      <td>Magnoliopsida</td>\n",
       "      <td>https://lab.plantnet.org/LifeCLEF/PlantCLEF202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>8002952</td>\n",
       "      <td>temp/582.jpg</td>\n",
       "      <td>ambrosia artemisiifolia l.</td>\n",
       "      <td>Ambrosia</td>\n",
       "      <td>Asteraceae</td>\n",
       "      <td>Asterales</td>\n",
       "      <td>Magnoliopsida</td>\n",
       "      <td>https://lab.plantnet.org/LifeCLEF/PlantCLEF202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>8002952</td>\n",
       "      <td>temp/583.jpg</td>\n",
       "      <td>ambrosia artemisiifolia l.</td>\n",
       "      <td>Ambrosia</td>\n",
       "      <td>Asteraceae</td>\n",
       "      <td>Asterales</td>\n",
       "      <td>Magnoliopsida</td>\n",
       "      <td>https://lab.plantnet.org/LifeCLEF/PlantCLEF202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>8002952</td>\n",
       "      <td>temp/584.jpg</td>\n",
       "      <td>ambrosia artemisiifolia l.</td>\n",
       "      <td>Ambrosia</td>\n",
       "      <td>Asteraceae</td>\n",
       "      <td>Asterales</td>\n",
       "      <td>Magnoliopsida</td>\n",
       "      <td>https://lab.plantnet.org/LifeCLEF/PlantCLEF202...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     classid    image_path                     species     genus      family  \\\n",
       "580  8002952  temp/580.jpg  ambrosia artemisiifolia l.  Ambrosia  Asteraceae   \n",
       "581  8002952  temp/581.jpg  ambrosia artemisiifolia l.  Ambrosia  Asteraceae   \n",
       "582  8002952  temp/582.jpg  ambrosia artemisiifolia l.  Ambrosia  Asteraceae   \n",
       "583  8002952  temp/583.jpg  ambrosia artemisiifolia l.  Ambrosia  Asteraceae   \n",
       "584  8002952  temp/584.jpg  ambrosia artemisiifolia l.  Ambrosia  Asteraceae   \n",
       "\n",
       "         order          class  \\\n",
       "580  Asterales  Magnoliopsida   \n",
       "581  Asterales  Magnoliopsida   \n",
       "582  Asterales  Magnoliopsida   \n",
       "583  Asterales  Magnoliopsida   \n",
       "584  Asterales  Magnoliopsida   \n",
       "\n",
       "                                      image_backup_url  \n",
       "580  https://lab.plantnet.org/LifeCLEF/PlantCLEF202...  \n",
       "581  https://lab.plantnet.org/LifeCLEF/PlantCLEF202...  \n",
       "582  https://lab.plantnet.org/LifeCLEF/PlantCLEF202...  \n",
       "583  https://lab.plantnet.org/LifeCLEF/PlantCLEF202...  \n",
       "584  https://lab.plantnet.org/LifeCLEF/PlantCLEF202...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"image_path\"] = [f\"{temp_dir}/{index}.jpg\" for index in data.index]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "IMAGE_SIZE = [224, 224] # default for MobileNetV2\n",
    "BATCH_SIZE = 32\n",
    "CHANNELS = 3\n",
    "\n",
    "train_df = data.sample(frac=0.8, random_state=123)  # 80% for training\n",
    "val_df = data.drop(train_df.index)                  # Remaining 20% for validation\n",
    "\n",
    "\n",
    "# Fit the label encoder and transform the 'classid' column\n",
    "label_encoder = LabelEncoder()\n",
    "data['classid_encoded'] = label_encoder.fit_transform(data['classid'])\n",
    "\n",
    "def preprocess_image(image_path: str, label: str) -> Tuple[tf.Tensor, tf.Tensor]:\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=CHANNELS)\n",
    "    image = tf.image.resize(image, IMAGE_SIZE)\n",
    "    image = image / 255.0  # Normalize pixel values\n",
    "    return image, label\n",
    "\n",
    "def df_to_dataset(dataframe: pd.DataFrame, shuffle=True, batch_size=BATCH_SIZE) -> tf.data.Dataset:\n",
    "    images = dataframe['image_path'].values\n",
    "    labels = dataframe['classid_encoded'].values\n",
    "    ds = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "    ds = ds.map(preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "    ds = ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "train_dataset = df_to_dataset(train_df, shuffle=True, batch_size=BATCH_SIZE)\n",
    "val_dataset = df_to_dataset(val_df, shuffle=False, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: REWRITE THIS, MAYBE DONT USE CLASSID AS LABEL BUT SPECIES\n",
    "\n",
    "import json\n",
    "\n",
    "classes = {label: class_name for label, class_name in enumerate(encoder.classes_)}\n",
    "with open('classes.json', 'w') as f:\n",
    "    json.dump(classes, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up MobileNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Load the MobileNetV2 model, excluding the top fully connected layer\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(*IMAGE_SIZE, CHANNELS))\n",
    "\n",
    "# Freeze the base model\n",
    "base_model.trainable = False\n",
    "\n",
    "# Add new layers on top\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)  # Large Dense layer for feature interpretation\n",
    "predictions = Dense(AMOUNT_OF_SPECIES, activation='softmax')(x)  # Final layer with softmax activation for AMOUNT_OF_SPECIES classes\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 373ms/step - accuracy: 0.3570 - loss: 2.2462 - val_accuracy: 0.6250 - val_loss: 1.0562\n",
      "Epoch 2/10\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6364 - loss: 0.9659 - val_accuracy: 0.4000 - val_loss: 1.9300\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-24 08:48:26.591042: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "/opt/homebrew/Cellar/python@3.11/3.11.9/Frameworks/Python.framework/Versions/3.11/lib/python3.11/contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n",
      "2024-04-24 08:48:26.651868: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 322ms/step - accuracy: 0.7577 - loss: 0.6519 - val_accuracy: 0.6979 - val_loss: 0.8288\n",
      "Epoch 4/10\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7273 - loss: 0.7825 - val_accuracy: 0.6000 - val_loss: 0.7288\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-24 08:48:30.889109: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-04-24 08:48:30.941137: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 321ms/step - accuracy: 0.9260 - loss: 0.2853 - val_accuracy: 0.7292 - val_loss: 0.7562\n",
      "Epoch 6/10\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9545 - loss: 0.2202 - val_accuracy: 0.6000 - val_loss: 0.6350\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-24 08:48:35.061374: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-04-24 08:48:35.116794: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 330ms/step - accuracy: 0.9460 - loss: 0.1987 - val_accuracy: 0.7500 - val_loss: 0.6893\n",
      "Epoch 8/10\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9545 - loss: 0.1559 - val_accuracy: 0.6000 - val_loss: 1.3977\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-24 08:48:39.351904: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-04-24 08:48:39.401719: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 315ms/step - accuracy: 0.9810 - loss: 0.1053 - val_accuracy: 0.7292 - val_loss: 0.6078\n",
      "Epoch 10/10\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.1101 - val_accuracy: 0.4000 - val_loss: 1.6608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-24 08:48:43.517978: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-04-24 08:48:43.572995: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    steps_per_epoch=len(train_df) // BATCH_SIZE,\n",
    "    epochs=10,\n",
    "    validation_data=val_dataset,\n",
    "    validation_steps=len(val_df) // BATCH_SIZE\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 260ms/step - accuracy: 0.7630 - loss: 0.5911\n",
      "Validation loss: 0.612205445766449, Validation accuracy: 0.7291666865348816\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_accuracy = model.evaluate(val_dataset, steps=len(val_df) // BATCH_SIZE)\n",
    "print(f'Validation loss: {val_loss}, Validation accuracy: {val_accuracy}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "save_model = True\n",
    "\n",
    "if save_model:\n",
    "    now = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "    model.save(f\"../models/model-{now}.keras\")\n",
    "else:\n",
    "    print(\"Model not saved. Set save_model to True to save the model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Save the classes like classes.json"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
