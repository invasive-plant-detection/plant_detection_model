{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# basic plant detection for starting Bachelor thesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data PlantCLEF2022_trusted_training_metadata.csv form /data/01_raw/PlantCLEF2022_trusted_training_metadata.csv\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "amount_pictures = 1_000\n",
    "file_path = \"../data/01_raw/PlantCLEF2022_trusted_training_metadata.csv\"\n",
    "try:\n",
    "    data = pd.read_csv(file_path, delimiter=\";\", nrows=amount_pictures)\n",
    "    if data.empty:\n",
    "        print(\"The CSV file is empty\")\n",
    "    else:\n",
    "        print(data.head())\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\n",
    "        f\"File not found: {file_path}. Please check the file path and that the file is downloaded.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## remove unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove column 'Unnamed: 0'\n",
    "data = data.drop(\n",
    "    columns=[\n",
    "        \"image_name\",\n",
    "        \"source\",\n",
    "        \"manual_tag\",\n",
    "        \"predicted_tag\",\n",
    "        \"predicted_tag_probability\",\n",
    "        \"original_url\",\n",
    "        \"license\",\n",
    "        \"publisher\",\n",
    "        \"gbif_occurrence_id\",\n",
    "        \"aggregator\",\n",
    "        \"dataset_key\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## delete already existing files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "temp_dir = \"temp\"\n",
    "\n",
    "# delete and create tmp dir to ensure it's empty\n",
    "os.system(f\"rm -rf {temp_dir}\")\n",
    "\n",
    "# Ensure the tmp/ directory exists\n",
    "os.makedirs(temp_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## download data per plant parallelized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "\n",
    "def download_image(index_url):\n",
    "    index, url = index_url\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        file_path = os.path.join(temp_dir, f\"{index}.jpg\")\n",
    "\n",
    "        with open(file_path, \"wb\") as file:\n",
    "            file.write(response.content)\n",
    "        # print(f\"Downloaded {url} to {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading {url}: {e}\")\n",
    "\n",
    "\n",
    "# Prepare a list of tuples containing the index and URL for each image\n",
    "index_url_list = [(index, row[\"image_backup_url\"]) for index, row in data.iterrows()]\n",
    "\n",
    "# Use ThreadPoolExecutor to download images in parallel\n",
    "with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "    executor.map(download_image, index_url_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add image path to metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"image_path\"] = [f\"{temp_dir}/{index}.jpg\" for index in data.index]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "target_size = (224, 224) # todo: is now random choose a good size afterwards\n",
    "\n",
    "# Function to load images\n",
    "def load_image(image_path: str) -> np.ndarray:\n",
    "    image = Image.open(image_path).convert('RGB')  # Ensure RGB format\n",
    "    image = image.resize(target_size)\n",
    "    image_array = np.asarray(image)\n",
    "    return image_array\n",
    "\n",
    "# Load images into arrays\n",
    "images = np.array([load_image(path) for path in data['image_path']])\n",
    "\n",
    "# Encode labels \n",
    "# transform into numerical values to train classifier\n",
    "encoder = LabelEncoder()\n",
    "data['encoded_labels'] = encoder.fit_transform(data['species'])  \n",
    "labels = data['encoded_labels'].values\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    images, labels, test_size=0.2, random_state=42  # Adjust test_size as needed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "num_classes = len(np.unique(y_train))\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape = (224, 224, 3)),\n",
    "    tf.keras.layers.Dense(128, activation='relu', kernel_initializer = tf.keras.initializers.he_normal),\n",
    "    tf.keras.layers.Dense(64, activation='relu', kernel_regularizer = tf.keras.regularizers.L2(0.01)),\n",
    "    tf.keras.layers.Dropout(rate=0.2),\n",
    "    tf.keras.layers.Dense(num_classes + 1, activation = 'softmax') # todo: +1 makes no sense?\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thoroughly examine y_train\n",
    "print(\"Unique labels: \", np.unique(y_train))\n",
    "print(\"Min label: \", np.min(y_train))\n",
    "print(\"Max label: \", np.max(y_train))\n",
    "print(\"Full y_train array:\\n\", y_train) \n",
    "\n",
    "# If there's an unexpected value, investigate further with:\n",
    "if np.max(y_train) >= 62: \n",
    "    for i, label in enumerate(y_train):\n",
    "        if label >= 62:\n",
    "            print(f\"Invalid label {label} found at index {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data\n",
    "mapping = {}\n",
    "\n",
    "for species, label in zip(df['species'], df['encoded_labels']):\n",
    "    if species not in mapping:\n",
    "        mapping[species] = label\n",
    "\n",
    "for species, label in mapping.items():\n",
    "    print(f\"{species}: {label}\")\n",
    "\n",
    "# Method 2: Using pandas.DataFrame.drop_duplicates \n",
    "unique_df = df[['species', 'encoded_labels']].drop_duplicates()\n",
    "\n",
    "for index, row in unique_df.iterrows():\n",
    "    print(f\"{row['species']}: {row['encoded_labels']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_8 (Flatten)         (None, 150528)            0         \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 128)               19267712  \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 63)                4095      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19280063 (73.55 MB)\n",
      "Trainable params: 19280063 (73.55 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"logs/my_model\"\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 3098.4048 - accuracy: 0.0362\n",
      "Epoch 2/30\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 8.2385 - accuracy: 0.0975\n",
      "Epoch 3/30\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 4.8034 - accuracy: 0.0988\n",
      "Epoch 4/30\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 4.7478 - accuracy: 0.0988\n",
      "Epoch 5/30\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 4.7133 - accuracy: 0.0988\n",
      "Epoch 6/30\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 4.8428 - accuracy: 0.0988\n",
      "Epoch 7/30\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 4.6354 - accuracy: 0.0988\n",
      "Epoch 8/30\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 4.6031 - accuracy: 0.0988\n",
      "Epoch 9/30\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 4.5760 - accuracy: 0.0988\n",
      "Epoch 10/30\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 4.5506 - accuracy: 0.0988\n",
      "Epoch 11/30\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 4.5263 - accuracy: 0.0988\n",
      "Epoch 12/30\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 4.5026 - accuracy: 0.0988\n",
      "Epoch 13/30\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 4.4811 - accuracy: 0.0988\n",
      "Epoch 14/30\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 4.4579 - accuracy: 0.0988\n",
      "Epoch 15/30\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 4.4364 - accuracy: 0.0988\n",
      "Epoch 16/30\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 4.4154 - accuracy: 0.0988\n",
      "Epoch 17/30\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 4.3950 - accuracy: 0.0988\n",
      "Epoch 18/30\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 4.3755 - accuracy: 0.0988\n",
      "Epoch 19/30\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 4.3555 - accuracy: 0.0988\n",
      "Epoch 20/30\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 4.3365 - accuracy: 0.0988\n",
      "Epoch 21/30\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 4.3276 - accuracy: 0.0988\n",
      "Epoch 22/30\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 4.2997 - accuracy: 0.0988\n",
      "Epoch 23/30\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 4.2816 - accuracy: 0.0988\n",
      "Epoch 24/30\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 4.2645 - accuracy: 0.0988\n",
      "Epoch 25/30\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 4.2474 - accuracy: 0.0988\n",
      "Epoch 26/30\n",
      "25/25 [==============================] - 1s 36ms/step - loss: 4.2308 - accuracy: 0.0988\n",
      "Epoch 27/30\n",
      "25/25 [==============================] - 1s 41ms/step - loss: 4.2144 - accuracy: 0.0787\n",
      "Epoch 28/30\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 4.1987 - accuracy: 0.0938\n",
      "Epoch 29/30\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 4.2029 - accuracy: 0.1013\n",
      "Epoch 30/30\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 4.1858 - accuracy: 0.0988\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=30, callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 - 0s - loss: 4.4181 - accuracy: 0.1050 - 112ms/epoch - 16ms/step\n",
      "\n",
      "Test accuracy: 0.10499999672174454\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test,  y_test, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
